
# See LICENSE for license details.

# This file is automatically generated. Do not edit.

#*****************************************************************************
# vand.vx_LMUL1SEW32.S
#-----------------------------------------------------------------------------
#
# Test vand.vx insnructions.
# With LMUL=1, SEW=32
#

#include "riscv_test.h"
#include "test_macros.h"

RVTEST_RV64UV

RVTEST_CODE_BEGIN


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, 4
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)

  TEST_CASE(2, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(3, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, 4
  vsetvli t1, t0, e32,m1,tu,ma
  li t2, 1
  vand.vx v1, v2, t2

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(6, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(7, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 4
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(10, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(11, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 4
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(14, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(15, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, 7
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(18, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(19, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, 7
  vsetvli t1, t0, e32,m1,tu,ma
  li t2, 1
  vand.vx v1, v2, t2

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(22, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(23, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 7
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(26, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(27, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 7
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(30, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(31, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, 8
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(34, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(35, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, 8
  vsetvli t1, t0, e32,m1,tu,ma
  li t2, 1
  vand.vx v1, v2, t2

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(38, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(39, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 8
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(42, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(43, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)


  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a2, tdat
  vle32.v v2, (a2)

  vsetvli t1, t0, e32,m1,ta,ma
  vle32.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 8
  vsetvli t1, t0, e32,m1,ta,ma
  li t2, 1
  vand.vx v1, v2, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e32,m1,ta,ma
  la a1, res
  vse32.v v1, (a1)


  TEST_CASE(46, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(47, t0, 0x1, ld t0, 0(a1); addi a1, a1, 8)




  TEST_PASSFAIL

RVTEST_CODE_END

  .data
RVTEST_DATA_BEGIN

res:
  .zero 144

tdat:
  .quad 0x1
  .quad 0x1
  .quad 0x3fffffff8
  .quad 0x700000000
  .quad 0xffffffffefffffff
  .quad 0x100000000
  .quad 0xefffffffffffffff
  .quad 0x100000000
  .quad 0x1

mask:
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555

RVTEST_DATA_END
